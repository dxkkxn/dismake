#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:t todo:t |:t
#+TITLE: CAHIER_DE_LABORATOIRE
#+DATE: <2023-11-12 mar.>
#+AUTHOR: Youssef BENJELLOUN EL KBIBI
#+EMAIL: 
#+LANGUAGE: fr
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.2.2 (Org mode 9.1.14)

* Gestion du code
** URL du gitlab de l'équipe
https://gitlab.ensimag.fr/benjelly/distrib-make
* Déploiement dans Grid 5000
Modifiez le nom d'utilisateur et ajoutez le path de votre clef ssh
#+BEGIN_SRC bash
    # On copie les fichiers vers grid5000
    ./copy_connect_g5k.sh $site # Remplacer par site de votre choix
    ssh $site # site spécifié dans copy_connect_g5k.sh
    ./setup.sh # On installe les dépendences
    # On déploie nos serveur et on lance le client
    # Ici remplacer $makefile par premier ou matrix, $nb_nodes par le nombre de noeuds, et $site par le site choisi avant
    python3 auto_deploy.py $makefile $nb_nodes $site
#+END_SRC

Par exemple pour lancer 4 worker nodes sur le makefile premier à Lyon, il suffit de faire :
#+BEGIN_SRC bash
    ./copy_connect_g5k.sh lyon
    ssh lyon
    ./setup.sh
    python3 auto_deploy.py premier 4 lyon
#+END_SRC

* Expérimentations

** TESTS PINGPONG
Avant de tester le make distribué, nous avons commencé par tester l'infrastructure en utilsant Go et grpc, ceci a été réalisé avec le code du commit 48ef0e37c1fdb69182a7cc1f3a77fc2579ec34ed.

** PREMIER TEST
Trois tests ont été effectués avec le Makefile distrib-make/scripts/tests_bench/premier_time_operations/ et ensuite une moyenne a été calculée pour obtenir les temps moyens d'exécution. La machine taurus à Lyon a été utilisée avec le commit 8e1a189507dac7c4003e24ecfca391b27c873212.
11,37	11,37	11,37
19,02	19,03	19,04
23,69	23,7	23,7
27,39	27,39	27,42
30,53	30,53	30,56
33,3	33,26	33,28
35,82	35,82	35,8
38,1	38,09	38,08
40,19	40,19	40,25
42,2	42,2	42,24
44,09	44,07	44,08
45,78	45,8	45,78
47,54	47,52	47,51
49,16	49,18	49,13
50,77	50,7	50,76
52,21	52,22	52,22
53,69	53,71	53,71
55,09	55,15	55,08
56,39	56,39	56,42
57,65	57,66	57,69
La moyenne de chaque exécution list<i>.txt est:
11,37; 19,03; 23,70; 27,40; 30,54; 33,28; 35,81; 38,09; 40,21; 42,21; 44,08; 45,79; 47,52; 49,16; 50,74; 52,22; 53,70; 55,11; 56,40; 57,67
De la même manière, trois autres tests de ce programme ont été effectués et le temps total a été mesuré :
814,33; 814,16; 814,19

** NFS ASSESSMENT
This test aimed at assessing how long did it take for writing operations to be performed with files up to 8MB.

For this to work well one must have a "./results" folder in place. The "nfs-test.c" file must be already compiled, in the same folder, with the name "nfs-test". This can achieved by running:

#+BEGIN_SRC sh
gcc -o nfs-test nfs-test.c
#+END_SRC

Then one can execute the following:

#+BEGIN_SRC sh
python run-file-evaluation.py
#+END_SRC

The results are going to be grouped per block size and per file size inside "./results" in the following fashion: "block-size_file-size.csv". Each file contains 32 executions of the test to get a good enough (alpha=0.05 implies a sample of around 32 values) estimation in terms of latency for the whole writing operation to be completed. The execution can take a while, so set aside a few hours for it to finish.

After the operations are done you can run:

#+BEGIN_SRC sh
/usr/sbin/nfsstat -m
#+END_SRC

Identify the mount point that contains the folder under which the test was performed (preferably the home folder) and then run:

#+BEGIN_SRC sh
/usr/sbin/nfsiostat
#+END_SRC

Now locate the mount point identified before, now you should be able to get some key info as such as the throughput in kB/s, the amount of read and write operations per second and some info regarding how long did it take on average for:
- the NFS client to receive a reply (avg RPC (ms))
- the entire RPC operation to complete (avg exe (ms))

All those tests were executed in the "nantes" site.

commit: d45258d4f6f45ed695c5d4660ba2fda3e212aa02

** MATRIX TEST
Pour le test de matrice, j'ai effectué le même type de mesure que pour le PREMIER TEST afin de mesurer le temps de chaque sous-tâche, avec le commit de hash 0e741ad1700d4dcb181b9d47a6b27d2560266883. Les tests séquentiels ont été effectués sur ma machine (MacBook Air M1) le 18 décembre.

* Fabrication des courbes de performances
Les courbes de performances sont tracées en utilisant la bibliothèque matplotlib de python. On lance le serveur go et puis on lance le client qui fera des ping-pong, et écrit sur la sortie standard les temps d'aller-retour mesurés, le débit calculé, la taille des message envoyés... Le programme metrics.py lit cette sortie et la parse afin de tirer les différentes données, et puis génère 3 graphiques différents : Le temps d'aller-retour en fonction de la taille des messages, le débit en fonction de la taille, et un histogramme représentant la distribution des temps d'aller-retour. Pour lancer ces mesure il suffit donc de lancer la commande : 
#+BEGIN_SRC sh
go run client/main.go 2>&1 | python3 metrics.py
#+END_SRC
