#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+OPTIONS: author:t broken-links:nil c:nil creator:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+OPTIONS: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+OPTIONS: timestamp:t title:t toc:t todo:t |:t
#+TITLE: CAHIER_DE_LABORATOIRE
#+DATE: <2023-11-12 mar.>
#+AUTHOR: Youssef BENJELLOUN EL KBIBI
#+EMAIL: 
#+LANGUAGE: fr
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 25.2.2 (Org mode 9.1.14)

* Gestion du code
** URL du gitlab de l'équipe
https://gitlab.ensimag.fr/benjelly/distrib-make
* Déploiement dans Grid 5000
Modifiez le nom d'utilisateur et ajoutez le path de votre clef ssh dans _copy\_connect.sh_
#+BEGIN_SRC bash
    # On copie les fichiers vers grid5000
    ./copy_connect_g5k.sh $site # Remplacer par site de votre choix
    ssh $site # site spécifié dans copy_connect_g5k.sh
    ./setup.sh # On installe les dépendences
    oarsub -l nodes=$NOMBRE_DES_NOEUDS -I
    ./make.sh $VOTRE_MAKEFILE
#+END_SRC

Par exemple pour lancer 4 worker nodes sur le makefile premier à Lyon, il suffit de faire :
#+BEGIN_SRC bash
    ./copy_connect_g5k.sh lyon
    ssh lyon
    ./setup.sh
    oarsub -l nodes=4 -I
    ./make.sh $VOTRE_MAKEFILE
#+END_SRC

Pour lancer les tests
#+BEGIN_SRC bash
    ./copy_connect_g5k.sh lyon
    ssh lyon
    ./setup.sh
    oarsub -l nodes=$NODES_NUM -I
    cd makefile
    make premier # or matrix
#+END_SRC
* Expérimentations

** TESTS PINGPONG
Avant de tester le make distribué, nous avons commencé par tester l'infrastructure en utilsant Go et grpc, ceci a été réalisé avec le code du commit 48ef0e37c1fdb69182a7cc1f3a77fc2579ec34ed.

** PREMIER TEST
Trois tests ont été effectués avec le Makefile distrib-make/scripts/tests_bench/premier_time_operations/ et ensuite une moyenne a été calculée pour obtenir les temps moyens d'exécution. La machine taurus à Lyon a été utilisée avec le commit 8e1a189507dac7c4003e24ecfca391b27c873212.
11,37	11,37	11,37
19,02	19,03	19,04
23,69	23,7	23,7
27,39	27,39	27,42
30,53	30,53	30,56
33,3	33,26	33,28
35,82	35,82	35,8
38,1	38,09	38,08
40,19	40,19	40,25
42,2	42,2	42,24
44,09	44,07	44,08
45,78	45,8	45,78
47,54	47,52	47,51
49,16	49,18	49,13
50,77	50,7	50,76
52,21	52,22	52,22
53,69	53,71	53,71
55,09	55,15	55,08
56,39	56,39	56,42
57,65	57,66	57,69
La moyenne de chaque exécution list<i>.txt est:
11,37; 19,03; 23,70; 27,40; 30,54; 33,28; 35,81; 38,09; 40,21; 42,21; 44,08; 45,79; 47,52; 49,16; 50,74; 52,22; 53,70; 55,11; 56,40; 57,67
De la même manière, trois autres tests de ce programme ont été effectués et le temps total a été mesuré :
814,33; 814,16; 814,19

** EVALUATION NFS
Ce test visait à évaluer le temps nécessaire pour effectuer les opérations d'écriture avec des fichiers allant jusqu'à 8 MB.

Pour que cela fonctionne bien, il faut avoir un dossier "./results" en place. Le fichier "nfs-test.c" doit être déjà compilé, dans le même dossier, sous le nom "nfs-test". Ceci peut être réalisé en exécutant :

#+BEGIN_SRC sh
gcc -o nfs-test nfs-test.c
#+END_SRC

On peut alors exécuter ce qui suit :

#+BEGIN_SRC sh
python run-file-evaluation.py
#+END_SRC

Les résultats vont être regroupés par taille de bloc et par taille de fichier dans "./results" de la manière suivante : "block-size_file-size.csv". Chaque fichier contient 32 exécutions du test pour obtenir une estimation suffisamment bonne (alpha=0,05 implique un échantillon d'environ 32 valeurs) en termes de latence pour que toute l'opération d'écriture soit terminée. L’exécution peut prendre un certain temps, alors prévoyez quelques heures pour qu’elle se termine.
 
Une fois les opérations terminées, vous pouvez exécuter :

#+BEGIN_SRC sh
/usr/sbin/nfsstat -m
#+END_SRC

Identifiez le point de montage qui contient le dossier sous lequel le test a été effectué (de préférence le dossier de départ), puis exécutez :

#+BEGIN_SRC sh
/usr/sbin/nfsiostat
#+END_SRC

Localisez maintenant le point de montage identifié précédemment. Vous devriez maintenant pouvoir obtenir des informations clés telles que le débit en Ko/s, le nombre d'opérations de lecture et d'écriture par seconde et des informations sur le temps que cela a pris en moyenne :
- le client NFS pour recevoir une réponse (moyenne RPC (ms))
- toute l'opération RPC à terminer (moyenne exe (ms))

Tous ces tests ont été exécutés sur le site de "nantes".

commit: d45258d4f6f45ed695c5d4660ba2fda3e212aa02

** MATRIX TEST
Pour le test de matrice, j'ai effectué le même type de mesure que pour le PREMIER TEST afin de mesurer le temps de chaque sous-tâche, avec le commit de hash 0e741ad1700d4dcb181b9d47a6b27d2560266883. Les tests séquentiels ont été effectués sur ma machine (MacBook Air M1) le 18 décembre.

* Fabrication des courbes de performances
Les courbes de performances sont tracées en utilisant la bibliothèque matplotlib de python. On lance le serveur go et puis on lance le client qui fera des ping-pong, et écrit sur la sortie standard les temps d'aller-retour mesurés, le débit calculé, la taille des message envoyés... Le programme metrics.py lit cette sortie et la parse afin de tirer les différentes données, et puis génère 3 graphiques différents : Le temps d'aller-retour en fonction de la taille des messages, le débit en fonction de la taille, et un histogramme représentant la distribution des temps d'aller-retour. Pour lancer ces mesure il suffit donc de lancer la commande : 
#+BEGIN_SRC sh
go run client/main.go 2>&1 | python3 metrics.py
#+END_SRC

* DERNIER TEST
Ici on va lancer le make distribué pour premier et matrix (fournis) 3 fois chacun, en augmentant le nombre de worker nodes de 1 à 20. A chaque exécution on mesure le temps, et on le stocke dans un fichier avec le nombre de workers utilisés. Pour un nombre de noeuds donné on calcule les moyenne des temps mesurés, et on génère les courbes d'évolution du temps d'exécution en fonction du nombre de workers.

#+BEGIN_SRC sh
./benchmark.sh
#+END_SRC

commit: 201a7e50328194c19f579174e4485f51f2e2329f
